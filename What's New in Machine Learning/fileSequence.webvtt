WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:01.516 --> 00:00:04.500 A:middle
[音乐]

00:00:08.516 --> 00:00:17.546 A:middle
[掌声]

00:00:18.046 --> 00:00:19.896 A:middle
&gt;&gt; 大家好 欢迎各位

00:00:20.656 --> 00:00:22.786 A:middle
我的名字是 Gaurav 今天

00:00:22.786 --> 00:00:24.306 A:middle
我们要讲的是

00:00:24.396 --> 00:00:27.456 A:middle
机器学习的新功能

00:00:29.696 --> 00:00:32.326 A:middle
成千上万的 App 都在用机器学习

00:00:33.356 --> 00:00:36.436 A:middle
你们正在制作的 App 非常棒

00:00:37.006 --> 00:00:39.846 A:middle
他们涉及到了用户生活的方方面面

00:00:40.456 --> 00:00:45.086 A:middle
医院里 医生正在使用

00:00:45.086 --> 00:00:47.326 A:middle
诸如 Butterfly iQ 这样的 App

00:00:47.326 --> 00:00:52.206 A:middle
来进行实时的医学诊断

00:00:52.416 --> 00:00:54.866 A:middle
体育界 教练正在使用

00:00:54.866 --> 00:00:57.646 A:middle
诸如 HomeCourt 这样的 App
来训练他们的运动员

00:00:58.576 --> 00:01:02.896 A:middle
在创造力方面 诸如

00:01:02.896 --> 00:01:04.936 A:middle
Pixelmator Pro 这样的 App 帮助其他

00:01:04.936 --> 00:01:07.686 A:middle
用户使用 ML 来增强他们的创造性

00:01:08.746 --> 00:01:10.366 A:middle
这只是其中一些例子

00:01:10.576 --> 00:01:12.446 A:middle
我们想要你们制作的

00:01:12.446 --> 00:01:14.746 A:middle
App 也能成为

00:01:14.746 --> 00:01:17.396 A:middle
这种优秀的 App

00:01:17.656 --> 00:01:19.686 A:middle
所以现在的问题是新功能是什么

00:01:20.556 --> 00:01:24.736 A:middle
那我就开始讲了

00:01:25.576 --> 00:01:28.896 A:middle
我们有很多的材料

00:01:28.896 --> 00:01:31.556 A:middle
所以一次或者两次会议是讲不完的

00:01:32.126 --> 00:01:36.856 A:middle
我们需要十次会议来讲解整个材料

00:01:38.316 --> 00:01:39.606 A:middle
我们还有一个

00:01:39.776 --> 00:01:43.216 A:middle
与机器学习中的设计相交叉的会议

00:01:44.556 --> 00:01:47.216 A:middle
我们也有每日实验室

00:01:47.216 --> 00:01:49.496 A:middle
你可以在这里和 Apple 机器学习

00:01:49.496 --> 00:01:51.746 A:middle
工程师一起相约探讨你的想法

00:01:53.116 --> 00:01:55.156 A:middle
当你在 App 中整合机器学习

00:01:55.156 --> 00:01:56.956 A:middle
我们都在这为你清除任何

00:01:56.956 --> 00:02:00.326 A:middle
你可能遇到的障碍

00:02:02.876 --> 00:02:04.776 A:middle
在所有的会议中

00:02:04.776 --> 00:02:07.016 A:middle
你将会看到 我们遵循简单的原则

00:02:08.356 --> 00:02:12.976 A:middle
我们想让机器学习变得越简单越好

00:02:12.976 --> 00:02:15.106 A:middle
我们正全神贯注于做此事

00:02:15.736 --> 00:02:17.766 A:middle
我们希望使其更灵活

00:02:17.766 --> 00:02:20.466 A:middle
以便你可以通过各种任务来完成它

00:02:21.436 --> 00:02:22.926 A:middle
我们希望使其更强大

00:02:22.976 --> 00:02:25.506 A:middle
以便你可以在你的设备上

00:02:25.506 --> 00:02:28.136 A:middle
运行最先进的机器学习模型

00:02:28.876 --> 00:02:32.976 A:middle
机器学习适用于每个人

00:02:32.976 --> 00:02:35.036 A:middle
不管你是研究员

00:02:35.036 --> 00:02:37.286 A:middle
还是一名机器学习的新手

00:02:38.776 --> 00:02:40.046 A:middle
通过在实验室中创建

00:02:40.046 --> 00:02:41.236 A:middle
你可以创建最先进的

00:02:41.236 --> 00:02:42.816 A:middle
以任务为中心的机器学习模型

00:02:44.526 --> 00:02:47.286 A:middle
我们产品的下一大支柱是 Domain API

00:02:49.256 --> 00:02:50.746 A:middle
Domain API 允许你用

00:02:50.746 --> 00:02:53.346 A:middle
Apple 的内置智能和模型

00:02:54.266 --> 00:02:55.506 A:middle
所以你不用担心

00:02:55.506 --> 00:02:57.426 A:middle
收集数据和建造模型了

00:02:57.646 --> 00:03:00.296 A:middle
简单地调用 API 即可完成

00:03:02.696 --> 00:03:04.326 A:middle
今年 我们正在大力

00:03:04.356 --> 00:03:05.806 A:middle
扩展我们的 Domain API

00:03:06.256 --> 00:03:08.676 A:middle
我们在视觉 文本 语音和声音中

00:03:09.106 --> 00:03:13.196 A:middle
都有 Domain API

00:03:13.406 --> 00:03:15.226 A:middle
现在先让我们来看看

00:03:15.276 --> 00:03:16.386 A:middle
其中的一些 API 

00:03:17.146 --> 00:03:19.746 A:middle
让我们先从视觉开始

00:03:20.976 --> 00:03:22.906 A:middle
视觉允许你推断

00:03:23.016 --> 00:03:24.716 A:middle
图像的内容

00:03:26.206 --> 00:03:27.386 A:middle
今年的新特点之一是

00:03:27.386 --> 00:03:29.036 A:middle
图像显著性

00:03:30.096 --> 00:03:31.576 A:middle
图像显著性可以帮你

00:03:31.576 --> 00:03:33.536 A:middle
识别图像中

00:03:33.536 --> 00:03:35.256 A:middle
最相关的区域

00:03:36.106 --> 00:03:40.146 A:middle
在这个例子中 就是人周围的区域

00:03:41.936 --> 00:03:43.056 A:middle
你可以用它来生成

00:03:43.056 --> 00:03:44.996 A:middle
缩略图或进行图像

00:03:44.996 --> 00:03:49.976 A:middle
裁剪 生成记忆 引导相机等等

00:03:50.046 --> 00:03:53.786 A:middle
今年我们要介绍的另外一个

00:03:53.786 --> 00:03:56.126 A:middle
重要特点是文本识别

00:03:57.666 --> 00:03:59.516 A:middle
现在你可以对文档

00:03:59.516 --> 00:04:01.476 A:middle
进行拍照 执行

00:04:01.476 --> 00:04:03.556 A:middle
透视校正 照明

00:04:03.556 --> 00:04:05.566 A:middle
校正和重新组织

00:04:05.616 --> 00:04:06.976 A:middle
设备上的文本

00:04:07.516 --> 00:04:13.986 A:middle
[掌声]

00:04:14.486 --> 00:04:18.666 A:middle
这是很成功的 但并不是全部

00:04:18.666 --> 00:04:19.796 A:middle
我们有图像内置

00:04:19.796 --> 00:04:22.016 A:middle
分类器 人体探测器 宠物

00:04:22.016 --> 00:04:24.036 A:middle
探测器 我们将

00:04:24.036 --> 00:04:27.046 A:middle
在两个视觉会议中介绍它们

00:04:31.036 --> 00:04:33.106 A:middle
下一个领域是自然语言

00:04:33.656 --> 00:04:36.356 A:middle
就像是你用视觉来

00:04:36.356 --> 00:04:38.376 A:middle
推断图像 你可以用

00:04:38.376 --> 00:04:43.076 A:middle
自然语言来推断文本

00:04:43.256 --> 00:04:46.166 A:middle
今年的新内容是内置的情感分析

00:04:46.166 --> 00:04:48.626 A:middle
所以你可以用一种

00:04:48.686 --> 00:04:50.616 A:middle
尊重隐私的方式在设备上

00:04:50.616 --> 00:04:53.216 A:middle
实时分析文本的情感

00:04:53.836 --> 00:04:55.296 A:middle
所以 举例来说 如果有人

00:04:55.296 --> 00:04:56.486 A:middle
输入这样的文本 我

00:04:56.566 --> 00:04:57.926 A:middle
对第二季结局感到很兴奋

00:04:57.926 --> 00:04:59.406 A:middle
这是一种积极的情感

00:05:02.656 --> 00:05:05.406 A:middle
这又是一个消极的情感

00:05:06.056 --> 00:05:08.656 A:middle
所以你可以实时

00:05:08.656 --> 00:05:10.006 A:middle
提供这种反馈

00:05:10.526 --> 00:05:14.516 A:middle
我们还首次

00:05:14.516 --> 00:05:17.386 A:middle
公开了内置的词嵌入

00:05:18.606 --> 00:05:20.096 A:middle
词嵌入可以让你

00:05:20.166 --> 00:05:21.666 A:middle
找到语义相近的单词

00:05:21.666 --> 00:05:23.426 A:middle
例如 雷暴这个词在语义上

00:05:23.426 --> 00:05:25.246 A:middle
非常接近多云

00:05:25.246 --> 00:05:28.406 A:middle
但是离鞋子和靴子相差甚远

00:05:28.896 --> 00:05:31.486 A:middle
词嵌入的一个重要使用案例是语义搜索

00:05:31.486 --> 00:05:35.246 A:middle
我们接下来给你举一个例子

00:05:35.456 --> 00:05:36.546 A:middle
自然语言将提前在

00:05:36.546 --> 00:05:38.446 A:middle
自然语言框架会议中

00:05:38.446 --> 00:05:40.086 A:middle
进行详细讨论

00:05:40.636 --> 00:05:45.836 A:middle
用户与 App 交互的第三种方式

00:05:45.836 --> 00:05:48.426 A:middle
是通过语言和声音

00:05:49.566 --> 00:05:51.076 A:middle
现在我们有了设备语音

00:05:51.106 --> 00:05:52.496 A:middle
支持 所以你可以在设备上

00:05:52.546 --> 00:05:54.986 A:middle
转录文本

00:05:54.986 --> 00:05:56.226 A:middle
你再也不用依赖

00:05:56.226 --> 00:05:59.266 A:middle
网络连接 我们也

00:05:59.266 --> 00:06:01.086 A:middle
有新的语音分析 API

00:06:01.436 --> 00:06:03.066 A:middle
它不仅可以告诉你讲话的内容

00:06:03.066 --> 00:06:05.926 A:middle
还可以告诉你讲话的方式

00:06:05.926 --> 00:06:07.066 A:middle
所以你可以区分

00:06:07.066 --> 00:06:08.486 A:middle
一个正常的声音和一个高度

00:06:08.576 --> 00:06:09.986 A:middle
紧张的声音

00:06:11.016 --> 00:06:12.916 A:middle
我们也有一个全新的声音

00:06:12.916 --> 00:06:14.396 A:middle
分析框架 我们会在

00:06:14.396 --> 00:06:15.936 A:middle
Create ML 大会上进行讨论

00:06:16.416 --> 00:06:21.496 A:middle
这些域中的

00:06:21.496 --> 00:06:24.146 A:middle
每一个域都有很多功能

00:06:24.146 --> 00:06:25.606 A:middle
你可以做的另一件事就是

00:06:25.606 --> 00:06:27.396 A:middle
无缝地组合这些域

00:06:28.216 --> 00:06:29.246 A:middle
让我给你们举一个例子

00:06:30.026 --> 00:06:33.176 A:middle
假设你想要构建一个

00:06:33.176 --> 00:06:35.566 A:middle
在图像上进行语义搜索的功能

00:06:35.676 --> 00:06:36.896 A:middle
这是一个非常复杂的功能

00:06:36.896 --> 00:06:38.746 A:middle
因此 如果一个用户搜索

00:06:38.746 --> 00:06:41.056 A:middle
雷暴 你不仅想

00:06:41.056 --> 00:06:42.366 A:middle
向他们提供

00:06:42.366 --> 00:06:43.886 A:middle
雷暴的结果 也想

00:06:44.026 --> 00:06:46.716 A:middle
提供天空和多云的结果

00:06:46.836 --> 00:06:49.756 A:middle
现在 你可以将视觉

00:06:49.756 --> 00:06:51.336 A:middle
和自然语言结合起来

00:06:51.336 --> 00:06:53.806 A:middle
仅需很少的代码就可实现此功能

00:06:55.176 --> 00:06:56.206 A:middle
这就是你将要做的

00:06:56.206 --> 00:06:58.146 A:middle
你将会在你的

00:06:58.146 --> 00:07:02.056 A:middle
图像上运行图像分类器

00:07:02.056 --> 00:07:03.606 A:middle
你也可以让它们使用内置的图像

00:07:03.606 --> 00:07:05.286 A:middle
分类器来生成标记

00:07:06.016 --> 00:07:08.886 A:middle
当用户输入

00:07:08.936 --> 00:07:10.356 A:middle
类似雷暴的单词 你

00:07:10.356 --> 00:07:11.926 A:middle
可以使用词嵌入来

00:07:11.926 --> 00:07:15.226 A:middle
生成相似的单词 并找到

00:07:15.226 --> 00:07:16.896 A:middle
与这些标记匹配的图像

00:07:17.626 --> 00:07:21.896 A:middle
而且这不是全部

00:07:21.896 --> 00:07:23.756 A:middle
你还可以将使用

00:07:23.756 --> 00:07:24.936 A:middle
Create ML 和 Domain API   

00:07:24.936 --> 00:07:26.746 A:middle
创建的自定义模型组合在一起

00:07:27.036 --> 00:07:28.646 A:middle
我们将在使用 Core ML 和 ARKit

00:07:28.646 --> 00:07:30.686 A:middle
创建伟大 App 的会议中

00:07:30.686 --> 00:07:32.996 A:middle
展示该示例

00:07:33.546 --> 00:07:37.426 A:middle
总之 Domain API

00:07:37.426 --> 00:07:38.766 A:middle
允许你利用 Apple 

00:07:38.896 --> 00:07:40.576 A:middle
内置智能和模型

00:07:40.856 --> 00:07:42.586 A:middle
使用 API 所以你无需

00:07:42.586 --> 00:07:44.266 A:middle
收据数据并制作模型

00:07:44.736 --> 00:07:45.776 A:middle
今年我们在

00:07:45.866 --> 00:07:48.046 A:middle
视觉自然语言

00:07:48.046 --> 00:07:49.976 A:middle
语音和声音 API 方面有了显著的扩展

00:07:56.336 --> 00:07:58.176 A:middle
现在让我们来谈谈 Core ML 3

00:07:58.526 --> 00:08:01.016 A:middle
我们产品的第三大支柱

00:08:03.536 --> 00:08:06.106 A:middle
现在我们所有的平台都

00:08:06.196 --> 00:08:10.156 A:middle
支持 Core ML

00:08:10.216 --> 00:08:11.396 A:middle
所有工作都在设备上完成

00:08:11.396 --> 00:08:13.936 A:middle
因此可以维护用户的隐私

00:08:14.716 --> 00:08:16.686 A:middle
Core ML 是硬件加速 

00:08:16.686 --> 00:08:18.466 A:middle
所以你可以这样做 你可以用它来

00:08:18.466 --> 00:08:19.726 A:middle
进行实时的机器学习

00:08:20.646 --> 00:08:22.586 A:middle
无需服务器

00:08:22.586 --> 00:08:23.656 A:middle
它总是可用的

00:08:24.356 --> 00:08:29.666 A:middle
Core ML 始终支持

00:08:29.666 --> 00:08:31.056 A:middle
各种机器学习

00:08:31.056 --> 00:08:33.006 A:middle
模型 包括经典的

00:08:33.006 --> 00:08:34.566 A:middle
广义线性模型 树集成

00:08:34.566 --> 00:08:35.976 A:middle
支持向量机

00:08:35.976 --> 00:08:40.395 A:middle
和卷积神经网络

00:08:40.395 --> 00:08:43.155 A:middle
和循环神经网络等网络

00:08:46.236 --> 00:08:48.596 A:middle
Core ML 的新功能是

00:08:48.596 --> 00:08:51.046 A:middle
模型灵活化和模型个性化

00:08:51.626 --> 00:08:54.016 A:middle
所以让我们来看看这些

00:08:55.956 --> 00:08:58.226 A:middle
Core ML 扩展了

00:08:58.226 --> 00:09:01.036 A:middle
对数据神经网络的支持

00:09:01.036 --> 00:09:03.686 A:middle
我们增加了对

00:09:03.686 --> 00:09:06.106 A:middle
100 多个神经网络层的支持

00:09:07.356 --> 00:09:09.046 A:middle
这意味着你几乎可以

00:09:09.046 --> 00:09:11.186 A:middle
携带 你可以将

00:09:11.186 --> 00:09:13.456 A:middle
最先进的机器学习

00:09:13.456 --> 00:09:15.486 A:middle
模型带入到你的 App 中

00:09:15.486 --> 00:09:16.926 A:middle
比如 ELMo BERT Wavenet

00:09:17.816 --> 00:09:18.586 A:middle
这是什么意思呢

00:09:20.136 --> 00:09:21.716 A:middle
假设你有一个 App

00:09:21.716 --> 00:09:22.906 A:middle
你想在你的 App 中

00:09:22.906 --> 00:09:24.056 A:middle
集成一个最先进的

00:09:24.056 --> 00:09:26.476 A:middle
问答系统

00:09:26.476 --> 00:09:28.156 A:middle
这样一来 当用户提出一个问题

00:09:28.156 --> 00:09:30.606 A:middle
今年的 WWDC 会有多少次大会

00:09:31.196 --> 00:09:33.336 A:middle
你可以使用 BERT 模型来完成

00:09:34.536 --> 00:09:35.796 A:middle
所以 该模型可以对语句

00:09:35.796 --> 00:09:38.116 A:middle
进行分析并给出反馈

00:09:38.146 --> 00:09:43.956 A:middle
结果答案是超过 100

00:09:43.956 --> 00:09:45.286 A:middle
除了自然语言以外

00:09:45.286 --> 00:09:47.756 A:middle
你还可以运行视觉方面的

00:09:47.756 --> 00:09:49.166 A:middle
最新进展比如

00:09:49.166 --> 00:09:51.666 A:middle
实例分割和音频生成

00:09:51.666 --> 00:09:53.256 A:middle
方面的最新进展

00:09:56.876 --> 00:09:58.606 A:middle
为了充分利用

00:09:58.606 --> 00:10:00.216 A:middle
Core ML 的扩展支持

00:10:00.266 --> 00:10:03.556 A:middle
我们正在更新我们的转换器

00:10:03.556 --> 00:10:04.986 A:middle
因此我们将有一个全新的

00:10:04.986 --> 00:10:06.276 A:middle
TensorFlow Core ML 转换器和

00:10:06.276 --> 00:10:09.566 A:middle
ONNX 支持的 ML 转换器即将推出

00:10:10.176 --> 00:10:14.756 A:middle
我们也在更新我们的模型库

00:10:14.756 --> 00:10:16.326 A:middle
在我们的模型库中

00:10:16.366 --> 00:10:18.726 A:middle
导入一些研究模型

00:10:18.726 --> 00:10:21.566 A:middle
以便你可以立即开始使用它们

00:10:22.686 --> 00:10:24.466 A:middle
因此代表着新模型的 ML 3 

00:10:24.466 --> 00:10:27.666 A:middle
和带有模型库的转换器

00:10:28.196 --> 00:10:29.526 A:middle
可以帮助你将

00:10:29.526 --> 00:10:31.316 A:middle
最前沿的 ML 引入到 App 中

00:10:32.216 --> 00:10:34.456 A:middle
现在 模型个性化是一个很大的特点

00:10:35.146 --> 00:10:36.836 A:middle
所以让我解释一下这是什么

00:10:37.336 --> 00:10:39.086 A:middle
所以到目前为止你可以看到

00:10:39.086 --> 00:10:41.106 A:middle
你已经使用 Create ML 来构建

00:10:41.106 --> 00:10:44.006 A:middle
模型 使用 Core ML 来部署

00:10:44.006 --> 00:10:47.616 A:middle
模型 但是 Core ML 3 的新功能是

00:10:47.846 --> 00:10:49.806 A:middle
设备模型个性化

00:10:50.266 --> 00:10:53.236 A:middle
你可以在设备上微调模型

00:10:53.966 --> 00:10:58.196 A:middle
我们在面部 ID 中

00:10:58.196 --> 00:11:00.466 A:middle
使用这种技术并

00:11:00.466 --> 00:11:01.276 A:middle
设置 Watch Face

00:11:02.026 --> 00:11:05.536 A:middle
所以事情就是这样发生的

00:11:05.756 --> 00:11:08.506 A:middle
今天你有了数据 你制作一个

00:11:08.566 --> 00:11:11.526 A:middle
ML 模型 你把它发送到你的

00:11:11.736 --> 00:11:13.776 A:middle
App 中 你的所有用户

00:11:13.776 --> 00:11:15.136 A:middle
都下载了相同的模型

00:11:15.706 --> 00:11:19.716 A:middle
这很棒 因为现在

00:11:20.196 --> 00:11:21.986 A:middle
用户不用上传他们的门户网站

00:11:22.346 --> 00:11:24.166 A:middle
你可以直接拍照

00:11:24.646 --> 00:11:25.956 A:middle
在设备上运行模型

00:11:25.956 --> 00:11:31.616 A:middle
得到诸如狗之类的推理

00:11:31.836 --> 00:11:34.126 A:middle
但是如果你正在尝试

00:11:34.126 --> 00:11:35.496 A:middle
处理一个对于每个用户来说都很独特

00:11:35.496 --> 00:11:36.526 A:middle
的概念 该怎么办

00:11:37.096 --> 00:11:38.826 A:middle
说一说我的狗这个概念吧

00:11:39.696 --> 00:11:41.006 A:middle
你可能希望用户

00:11:41.006 --> 00:11:42.866 A:middle
在图片库中找到他们自己的狗的照片

00:11:42.916 --> 00:11:44.456 A:middle
而不是他们拍的

00:11:44.456 --> 00:11:47.216 A:middle
所有狗的照片

00:11:47.336 --> 00:11:49.156 A:middle
而且每个用户的狗看起来都如此不同

00:11:49.156 --> 00:11:50.426 A:middle
例如 有人可能有

00:11:50.486 --> 00:11:51.706 A:middle
金毛猎犬 有的人可能

00:11:52.196 --> 00:11:54.386 A:middle
有斗牛犬 啊 这就是

00:11:54.386 --> 00:11:56.976 A:middle
我的傻狗

00:11:58.976 --> 00:12:01.546 A:middle
那么 我们应该怎么做呢

00:12:02.746 --> 00:12:05.106 A:middle
所以对于用户 1 来说我们想要的

00:12:05.106 --> 00:12:06.936 A:middle
需要的是带有这只狗的

00:12:06.936 --> 00:12:09.076 A:middle
图像分类器 说这是他们的狗

00:12:10.286 --> 00:12:12.326 A:middle
对用户 2 来说 这是英国

00:12:12.326 --> 00:12:14.906 A:middle
斗牛犬 这是第三只狗

00:12:18.576 --> 00:12:21.286 A:middle
所以为了做到这一点 其中一种

00:12:21.286 --> 00:12:23.886 A:middle
方法是使用基于服务器的方法

00:12:23.916 --> 00:12:26.126 A:middle
所以你可能要求

00:12:26.636 --> 00:12:32.476 A:middle
每个用户在云端上传照片

00:12:32.476 --> 00:12:34.496 A:middle
服务器为每个用户生成模型

00:12:34.496 --> 00:12:39.466 A:middle
然后将它们发回来

00:12:39.466 --> 00:12:42.606 A:middle
不幸的是 这种方法存在隐私问题

00:12:42.606 --> 00:12:45.006 A:middle
你的用户可能并不乐意

00:12:45.266 --> 00:12:47.236 A:middle
将他们的照片上传到你的

00:12:47.236 --> 00:12:48.496 A:middle
服务器中 这样你就无法

00:12:48.496 --> 00:12:49.516 A:middle
获得他们的照片

00:12:50.606 --> 00:12:51.866 A:middle
你必须设置服务器

00:12:51.916 --> 00:12:53.296 A:middle
所以需要一些成本

00:12:53.846 --> 00:12:56.346 A:middle
我们假设你有一百万用户

00:12:56.346 --> 00:12:58.036 A:middle
我们也真诚的希望你有

00:12:58.036 --> 00:12:59.396 A:middle
你就必须得制作数百万个

00:12:59.396 --> 00:13:00.776 A:middle
这样的模型 然后随着时间的推移

00:13:00.836 --> 00:13:02.966 A:middle
来追踪它们

00:13:05.176 --> 00:13:07.356 A:middle
使用 Core ML 3 你就可以

00:13:07.356 --> 00:13:09.186 A:middle
在设备上进行更多个性化设置

00:13:09.396 --> 00:13:11.776 A:middle
所以如果你设备上有

00:13:11.776 --> 00:13:13.886 A:middle
训练数据 你就可以

00:13:13.886 --> 00:13:15.906 A:middle
简单地使用它来微调

00:13:15.906 --> 00:13:17.146 A:middle
设备上的模型

00:13:17.946 --> 00:13:23.366 A:middle
所以你之前使用 LMH

00:13:23.366 --> 00:13:27.156 A:middle
来进行推理 如今你可以

00:13:27.156 --> 00:13:28.936 A:middle
从用户那里获取标签数据反馈

00:13:28.936 --> 00:13:30.396 A:middle
提供一些

00:13:30.396 --> 00:13:32.386 A:middle
训练数据 微调

00:13:32.386 --> 00:13:34.276 A:middle
设备上的模型

00:13:35.516 --> 00:13:42.226 A:middle
[掌声]

00:13:42.726 --> 00:13:44.256 A:middle
每个用户都有一个

00:13:44.406 --> 00:13:46.006 A:middle
个性化模型

00:13:48.176 --> 00:13:50.826 A:middle
我们尊重每个用户的隐私

00:13:50.826 --> 00:13:52.696 A:middle
所以你不必放置服务器

00:13:53.386 --> 00:13:56.386 A:middle
所以 Core ML 3 支持

00:13:56.386 --> 00:13:59.326 A:middle
神经网络的设备个性化

00:13:59.786 --> 00:14:01.146 A:middle
我们也支持近邻

00:14:01.276 --> 00:14:03.346 A:middle
算法 这个可以

00:14:03.346 --> 00:14:05.246 A:middle
晚上在后台进行

00:14:08.536 --> 00:14:10.276 A:middle
因此 为了总结和结束我们的

00:14:10.356 --> 00:14:13.046 A:middle
会议 我们看到 Create ML 这个全新的

00:14:13.046 --> 00:14:16.006 A:middle
App 来构建 ML 模型 我们

00:14:16.006 --> 00:14:17.556 A:middle
在 Domain API 中进行了重大 

00:14:17.556 --> 00:14:21.126 A:middle
扩展 Core ML

00:14:21.196 --> 00:14:22.586 A:middle
也变得更加灵活 现在

00:14:22.586 --> 00:14:24.666 A:middle
支持设备个性化

00:14:25.206 --> 00:14:29.016 A:middle
你可以在我们的开发者网站大会 209

00:14:29.016 --> 00:14:30.796 A:middle
上找到更多信息

00:14:30.796 --> 00:14:33.966 A:middle
我们希望你们

00:14:33.996 --> 00:14:36.176 A:middle
像我们一样对这些技术感兴趣

00:14:36.566 --> 00:14:38.226 A:middle
我期待在实验室见到你

00:14:38.366 --> 00:14:38.706 A:middle
谢谢

00:14:39.516 --> 00:14:43.500 A:middle
[掌声]


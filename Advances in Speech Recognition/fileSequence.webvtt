WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:00.506 --> 00:00:05.916 A:middle
[音乐]

00:00:06.416 --> 00:00:08.846 A:middle
&gt;&gt; 大家好 我是 Neha Agrawal

00:00:08.846 --> 00:00:11.426 A:middle
是一名语音识别软件工程师

00:00:12.426 --> 00:00:14.776 A:middle
2016 年 我们推出了

00:00:14.776 --> 00:00:16.436 A:middle
语音识别框架供开发者使用

00:00:16.686 --> 00:00:19.686 A:middle
以满足他们的语音识别需求

00:00:20.326 --> 00:00:22.096 A:middle
如果你对这一框架

00:00:22.096 --> 00:00:24.096 A:middle
还不了解 我强烈建议你

00:00:24.316 --> 00:00:25.876 A:middle
观看这场关于语音识别 API 的会议

00:00:25.876 --> 00:00:28.166 A:middle
主讲人是我的同事

00:00:28.316 --> 00:00:29.246 A:middle
Henry Mason

00:00:31.066 --> 00:00:32.695 A:middle
本视频中 我们会探讨

00:00:32.695 --> 00:00:35.426 A:middle
这些 API 取得的新进展

00:00:35.426 --> 00:00:36.906 A:middle
我们现在开始

00:00:39.216 --> 00:00:42.206 A:middle
语音识别现已支持 macOS

00:00:43.036 --> 00:00:44.706 A:middle
既支持 AppKit

00:00:44.706 --> 00:00:47.716 A:middle
也支持 Mac 上的 iPad App

00:00:48.886 --> 00:00:52.266 A:middle
而且和 iOS 一样支持五十多种语言

00:00:53.816 --> 00:00:55.756 A:middle
你需要用户授权

00:00:55.756 --> 00:00:57.856 A:middle
访问麦克风

00:00:57.976 --> 00:00:59.616 A:middle
从而录制语音

00:01:02.876 --> 00:01:05.596 A:middle
除了在 macOS 上支持

00:01:05.596 --> 00:01:08.366 A:middle
语音识别外 我们现在还

00:01:08.366 --> 00:01:10.056 A:middle
允许开发者

00:01:10.056 --> 00:01:12.026 A:middle
为重视隐私的 App

00:01:12.026 --> 00:01:13.936 A:middle
在设备本地运行语音识别

00:01:14.646 --> 00:01:17.876 A:middle
支持设备本地运行

00:01:17.876 --> 00:01:20.586 A:middle
用户的数据就不会传到 Apple 的服务器

00:01:22.096 --> 00:01:24.156 A:middle
你的 App 不再需要

00:01:24.446 --> 00:01:27.136 A:middle
依赖网络连接

00:01:27.136 --> 00:01:29.196 A:middle
也不会消耗流量

00:01:31.216 --> 00:01:34.026 A:middle
但同时 要权衡许多因素

00:01:34.736 --> 00:01:37.426 A:middle
在设备本地运行时 识别很准确

00:01:37.426 --> 00:01:39.536 A:middle
在服务器上运行

00:01:39.536 --> 00:01:41.416 A:middle
效果更好 因为可以连续学习

00:01:41.666 --> 00:01:43.896 A:middle
但服务器上的语音识别

00:01:43.896 --> 00:01:46.246 A:middle
会受请求数量和

00:01:46.246 --> 00:01:48.196 A:middle
语音时长的限制

00:01:48.976 --> 00:01:50.496 A:middle
而在设备本地识别

00:01:50.876 --> 00:01:52.436 A:middle
则不会受到这些限制

00:01:53.726 --> 00:01:54.776 A:middle
服务器支持的

00:01:54.776 --> 00:01:57.256 A:middle
语言种类远大于

00:01:57.256 --> 00:01:58.536 A:middle
设备本地识别

00:01:59.846 --> 00:02:02.126 A:middle
而且 如果服务器不可用

00:02:02.126 --> 00:02:04.426 A:middle
且支持设备本地识别

00:02:04.426 --> 00:02:06.376 A:middle
服务模式会自动

00:02:06.376 --> 00:02:08.276 A:middle
变为设备本地识别

00:02:09.156 --> 00:02:11.736 A:middle
所有配备 A9 或更新处理器的

00:02:12.156 --> 00:02:13.196 A:middle
iPhone 和 iPad

00:02:13.196 --> 00:02:15.746 A:middle
以及所有的 Mac 均支持此功能

00:02:16.776 --> 00:02:18.086 A:middle
设备本地识别

00:02:18.086 --> 00:02:19.856 A:middle
现支持超过 10 种语言

00:02:20.426 --> 00:02:23.746 A:middle
接下来 我们来看看如何

00:02:23.976 --> 00:02:25.876 A:middle
用代码实现设备本地语音识别

00:02:26.536 --> 00:02:29.016 A:middle
要识别预先录制的音频

00:02:29.386 --> 00:02:30.986 A:middle
我们首先创建

00:02:30.986 --> 00:02:33.066 A:middle
SFSpeechRecognizer 对象

00:02:33.066 --> 00:02:35.096 A:middle
并检查语音识别

00:02:35.096 --> 00:02:36.856 A:middle
能否用于这一对象

00:02:39.206 --> 00:02:40.346 A:middle
如果语音识别可用

00:02:40.346 --> 00:02:42.516 A:middle
我们就可以

00:02:42.516 --> 00:02:44.376 A:middle
使用音频文件 URL 创建

00:02:44.376 --> 00:02:47.026 A:middle
识别请求 并开始识别

00:02:49.676 --> 00:02:51.896 A:middle
要使用设备本地识别

00:02:51.896 --> 00:02:53.616 A:middle
首先要检查

00:02:53.616 --> 00:02:55.416 A:middle
设备是否支持

00:02:55.416 --> 00:02:57.396 A:middle
本地识别

00:02:57.606 --> 00:02:59.446 A:middle
然后设置请求对象的

00:02:59.446 --> 00:03:01.396 A:middle
requiresOnDeviceRecognition 属性

00:03:03.136 --> 00:03:04.586 A:middle
我们看过了这部分代码

00:03:04.586 --> 00:03:07.006 A:middle
接下来看看得到的结果

00:03:07.466 --> 00:03:11.466 A:middle
从 iOS 10 开始

00:03:11.466 --> 00:03:13.016 A:middle
识别结果中

00:03:13.016 --> 00:03:14.616 A:middle
提供了语音转写

00:03:14.966 --> 00:03:16.486 A:middle
不同版本的识别文本

00:03:16.786 --> 00:03:19.096 A:middle
置信水平和时间信息

00:03:20.636 --> 00:03:22.146 A:middle
现在我们要

00:03:22.146 --> 00:03:23.616 A:middle
进一步扩充语音识别结果

00:03:26.776 --> 00:03:29.186 A:middle
语音速率按每分钟词数衡量

00:03:29.186 --> 00:03:31.396 A:middle
一个人说话的快慢程度

00:03:33.366 --> 00:03:35.006 A:middle
平均停顿时长衡量

00:03:35.276 --> 00:03:37.336 A:middle
词与词之间停顿的平均长度

00:03:37.906 --> 00:03:41.086 A:middle
语音分析特征

00:03:41.306 --> 00:03:43.196 A:middle
包含语音特征的

00:03:43.196 --> 00:03:44.566 A:middle
不同参数

00:03:46.116 --> 00:03:47.906 A:middle
语音分析可以

00:03:47.906 --> 00:03:49.416 A:middle
帮助理解四种特征

00:03:50.186 --> 00:03:52.726 A:middle
基频微扰衡量语音中音高的变化

00:03:53.446 --> 00:03:55.296 A:middle
你可以借助语音分析

00:03:55.296 --> 00:03:57.066 A:middle
用百分比的形式

00:03:57.066 --> 00:03:59.816 A:middle
理解语音中基频微扰的程度

00:04:02.926 --> 00:04:04.886 A:middle
音量大小的变化 你可以

00:04:04.886 --> 00:04:06.706 A:middle
借助语音分析 以分贝为单位

00:04:06.706 --> 00:04:11.946 A:middle
理解语音中振幅微扰的程度

00:04:12.096 --> 00:04:13.376 A:middle
我们来听一些音频样本

00:04:13.376 --> 00:04:14.466 A:middle
来理解高基频微扰

00:04:14.466 --> 00:04:16.166 A:middle
和高振幅微扰

00:04:16.166 --> 00:04:17.125 A:middle
音频是什么样的

00:04:17.606 --> 00:04:19.526 A:middle
首先 我们来听一段

00:04:19.526 --> 00:04:20.276 A:middle
正常语音

00:04:20.866 --> 00:04:21.546 A:middle
&gt;&gt; Apple

00:04:23.276 --> 00:04:25.236 A:middle
&gt;&gt; 现在来听一段修改过的语音
	
00:04:25.956 --> 00:04:26.846 A:middle
&gt;&gt; Apple

00:04:27.926 --> 00:04:29.176 A:middle
&gt;&gt; 下一项特征是音高

00:04:29.966 --> 00:04:31.976 A:middle
音高衡量的是

00:04:31.976 --> 00:04:33.286 A:middle
音调的高低

00:04:33.656 --> 00:04:36.266 A:middle
一般来说 女性和儿童的音高更高

00:04:37.496 --> 00:04:39.426 A:middle
发音则用来衡量

00:04:39.776 --> 00:04:41.766 A:middle
语音中发音的位置

00:04:42.316 --> 00:04:44.956 A:middle
语音分析特征

00:04:44.956 --> 00:04:46.516 A:middle
因人而异

00:04:46.516 --> 00:04:49.926 A:middle
也随时间和场合变化

00:04:50.636 --> 00:04:52.506 A:middle
例如 如果讲话人较为疲惫

00:04:52.506 --> 00:04:54.876 A:middle
那么语音分析特征

00:04:54.876 --> 00:04:56.616 A:middle
便与不疲惫时有所不同

00:04:57.466 --> 00:04:59.346 A:middle
而且 随着讲话人的

00:04:59.346 --> 00:05:00.996 A:middle
说话对象发生变化

00:05:00.996 --> 00:05:01.976 A:middle
这些特征也会随之改变

00:05:04.416 --> 00:05:06.556 A:middle
这些新的结果是

00:05:06.556 --> 00:05:08.436 A:middle
SFTranscription 对象的一部分

00:05:08.436 --> 00:05:10.016 A:middle
而且会定期提供

00:05:10.556 --> 00:05:12.776 A:middle
我们会在最后 也就是

00:05:12.986 --> 00:05:14.586 A:middle
在 isFinal 标志发送后提供

00:05:14.996 --> 00:05:16.586 A:middle
但也可以在此之前看到

00:05:17.306 --> 00:05:19.806 A:middle
你可以如幻灯片所示

00:05:19.806 --> 00:05:21.796 A:middle
访问 speakingRate 和 averagePauseDuration

00:05:23.736 --> 00:05:26.566 A:middle
要访问语音分析

00:05:26.566 --> 00:05:28.446 A:middle
你要先访问

00:05:28.446 --> 00:05:30.346 A:middle
SFTranscription 的 segment 对象

00:05:30.586 --> 00:05:32.256 A:middle
之后如幻灯片所示

00:05:32.256 --> 00:05:32.846 A:middle
进行访问

00:05:34.636 --> 00:05:37.846 A:middle
总而言之 我们有三项重大进展

00:05:38.506 --> 00:05:40.326 A:middle
你现在可以在 macOS 中编写

00:05:40.656 --> 00:05:42.366 A:middle
使用语音识别 API 的 App

00:05:43.546 --> 00:05:45.066 A:middle
语音识别可以在设备本地运行

00:05:45.066 --> 00:05:47.606 A:middle
更好地保护隐私

00:05:48.386 --> 00:05:50.696 A:middle
最后 你可以访问

00:05:50.696 --> 00:05:52.686 A:middle
语音分析特征

00:05:52.686 --> 00:05:55.136 A:middle
从而更好地理解语音特征

00:05:57.176 --> 00:06:01.006 A:middle
若要了解更多信息 请访问本会议的网站

00:06:01.006 --> 00:06:01.976 A:middle
感谢观看

